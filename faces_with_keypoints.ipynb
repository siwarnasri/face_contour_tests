{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import glob\n",
    "from sklearn import cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'D:/dataset/youtube_faces_with_keypoints_small.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-48892c131c67>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mvideoDF\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'D:/dataset/youtube_faces_with_keypoints_small.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mvideoDF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lina\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 678\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lina\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    438\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 440\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    441\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lina\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    785\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    786\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 787\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    788\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    789\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lina\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1013\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1014\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1015\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1016\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lina\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1706\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'usecols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1707\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1708\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1709\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1710\u001b[0m         \u001b[0mpassed_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnames\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: File b'D:/dataset/youtube_faces_with_keypoints_small.csv' does not exist"
     ]
    }
   ],
   "source": [
    "videoDF = pd.read_csv('D:/dataset/youtube_faces_with_keypoints_small.csv')\n",
    "videoDF.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary that maps videoIDs to full file paths\n",
    "npzFilesFullPath = glob.glob('D:/dataset/youtube_faces_*/*.npz')\n",
    "\n",
    "videoIDs = [x.split(\"\\\\\")[-1].split('.')[0] for x in npzFilesFullPath]\n",
    "fullPaths = {}\n",
    "\n",
    "for videoID, fullPath in zip(videoIDs, npzFilesFullPath):\n",
    "    fullPaths[videoID] = fullPath\n",
    "\n",
    "# remove from the large csv file all videos that weren't uploaded yet\n",
    "videoDF = videoDF.loc[videoDF.loc[:,'videoID'].isin(fullPaths.keys()),:].reset_index(drop=True)\n",
    "#print(videoDF)\n",
    "print('Number of Videos is %d' %(videoDF.shape[0]))\n",
    "print('Number of Unique Individuals is %d' %(len(videoDF['personName'].unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videoDF = pd.read_csv('D:/dataset/youtube_faces_with_keypoints_large.csv')\n",
    "videoDF.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary that maps videoIDs to full file paths\n",
    "npzFilesFullPath = glob.glob('D:/dataset/youtube_faces_*/*.npz')\n",
    "\n",
    "videoIDs = [x.split(\"\\\\\")[-1].split('.')[0] for x in npzFilesFullPath]\n",
    "fullPaths = {}\n",
    "\n",
    "for videoID, fullPath in zip(videoIDs, npzFilesFullPath):\n",
    "    fullPaths[videoID] = fullPath\n",
    "\n",
    "# remove from the large csv file all videos that weren't uploaded yet\n",
    "videoDF = videoDF.loc[videoDF.loc[:,'videoID'].isin(fullPaths.keys()),:].reset_index(drop=True)\n",
    "#print(videoDF)\n",
    "print('Number of Videos is %d' %(videoDF.shape[0]))\n",
    "print('Number of Unique Individuals is %d' %(len(videoDF['personName'].unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# overview of the contents of the dataset\n",
    "groupedByPerson = videoDF.groupby(\"personName\")\n",
    "numVidsPerPerson = groupedByPerson.count()['videoID']\n",
    "groupedByPerson.count().sort_values('videoID', axis=0, ascending=False)\n",
    "\n",
    "plt.close('all')\n",
    "plt.figure(figsize=(25,20))\n",
    "plt.subplot(2,2,1)\n",
    "plt.hist(x=numVidsPerPerson,bins=0.5+np.arange(numVidsPerPerson.min()-1,numVidsPerPerson.max()+1))\n",
    "plt.title('Number of Videos per Person',fontsize=30); \n",
    "plt.xlabel('Number of Videos',fontsize=25); plt.ylabel('Number of People',fontsize=25)\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "plt.hist(x=videoDF['videoDuration'],bins=28);\n",
    "plt.title('Distribution of Video Duration',fontsize=30); \n",
    "plt.xlabel('duration [frames]',fontsize=25); plt.ylabel('Number of Videos',fontsize=25)\n",
    "plt.xlim(videoDF['videoDuration'].min()-2,videoDF['videoDuration'].max()+2)\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "plt.scatter(x=videoDF['imageWidth'], y=videoDF['imageHeight'])\n",
    "plt.title('Distribution of Image Sizes',fontsize=30)\n",
    "plt.xlabel('Image Width [pixels]',fontsize=25); plt.ylabel('Image Height [pixels]',fontsize=25)\n",
    "plt.xlim(0,videoDF['imageWidth'].max() +15)\n",
    "plt.ylim(0,videoDF['imageHeight'].max()+15)\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "averageFaceSize_withoutNaNs = np.array(videoDF['averageFaceSize'])\n",
    "averageFaceSize_withoutNaNs = averageFaceSize_withoutNaNs[np.logical_not(np.isnan(averageFaceSize_withoutNaNs))]\n",
    "plt.hist(averageFaceSize_withoutNaNs, bins=28)\n",
    "plt.title('Distribution of Average Face Sizes ',fontsize=30)\n",
    "plt.xlabel('Average Face Size [pixels]',fontsize=25); plt.ylabel('Number of Videos',fontsize=25);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import YouTubeVideo\n",
    "YouTubeVideo('8FdSHl4oNIM',width=640, height=480)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show several frames from each video and overlay 2D keypoints\n",
    "np.random.seed(3)\n",
    "numVideos = 4\n",
    "framesToShowFromVideo = np.array([0.1,0.5,0.9])\n",
    "numFramesPerVideo = len(framesToShowFromVideo)\n",
    "\n",
    "# define which points need to be connected with a line\n",
    "jawPoints          = [ 0,17]\n",
    "rigthEyebrowPoints = [17,22]\n",
    "leftEyebrowPoints  = [22,27]\n",
    "noseRidgePoints    = [27,31]\n",
    "noseBasePoints     = [31,36]\n",
    "rightEyePoints     = [36,42]\n",
    "leftEyePoints      = [42,48]\n",
    "outerMouthPoints   = [48,60]\n",
    "innerMouthPoints   = [60,68]\n",
    "\n",
    "listOfAllConnectedPoints = [jawPoints,rigthEyebrowPoints,leftEyebrowPoints,\n",
    "                            noseRidgePoints,noseBasePoints,\n",
    "                            rightEyePoints,leftEyePoints,outerMouthPoints,innerMouthPoints]\n",
    "\n",
    "# select a random subset of 'numVideos' from the available videos\n",
    "randVideoIDs = videoDF.loc[np.random.choice(videoDF.index,size=numVideos,replace=False),'videoID']\n",
    "\n",
    "fig, axArray = plt.subplots(nrows=numVideos,ncols=numFramesPerVideo,figsize=(14,18))\n",
    "for i, videoID in enumerate(randVideoIDs):\n",
    "    # load video\n",
    "    videoFile = np.load(fullPaths[videoID])\n",
    "    colorImages = videoFile['colorImages']\n",
    "    boundingBox = videoFile['boundingBox']\n",
    "    landmarks2D = videoFile['landmarks2D']\n",
    "    landmarks3D = videoFile['landmarks3D']\n",
    "\n",
    "    # select frames and show their content\n",
    "    selectedFrames = (framesToShowFromVideo*(colorImages.shape[3]-1)).astype(int)\n",
    "    for j, frameInd in enumerate(selectedFrames):\n",
    "        axArray[i][j].imshow(colorImages[:,:,:,frameInd])\n",
    "        axArray[i][j].scatter(x=landmarks2D[:,0,frameInd],y=landmarks2D[:,1,frameInd],s=9,c='r')\n",
    "        for conPts in listOfAllConnectedPoints:\n",
    "            xPts = landmarks2D[conPts[0]:conPts[-1],0,frameInd]\n",
    "            yPts = landmarks2D[conPts[0]:conPts[-1],1,frameInd]\n",
    "        \n",
    "            if conPts == [36,42] or conPts == [42,48] or conPts == [48,60] or conPts == [60,68]:\n",
    "                xPts=np.concatenate((xPts, [xPts[0]]))\n",
    "                yPts=np.concatenate((yPts, [yPts[0]]))\n",
    "            \n",
    "            axArray[i][j].plot(xPts,yPts,c='w',lw=1)\n",
    "        axArray[i][j].set_title('\"%s\" (t=%d)' %(videoID,frameInd), fontsize=12)\n",
    "        axArray[i][j].set_axis_off()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def points_vis():\n",
    "    # show several frames from each video and overlay 2D keypoints\n",
    "    #np.random.seed(2)\n",
    "    numVideos = 5\n",
    "    framesToShowFromVideo = np.array([0.1,0.5,0.9])\n",
    "    numFramesPerVideo = len(framesToShowFromVideo)\n",
    "\n",
    "    # define which points need to be connected with a line\n",
    "    jawPoints          = [ 0,17]\n",
    "    rigthEyebrowPoints = [17,22]\n",
    "    leftEyebrowPoints  = [22,27]\n",
    "    noseRidgePoints    = [27,31]\n",
    "    noseBasePoints     = [31,36]\n",
    "    rightEyePoints     = [36,42]\n",
    "    leftEyePoints      = [42,48]\n",
    "    outerMouthPoints   = [48,60]\n",
    "    innerMouthPoints   = [60,68]\n",
    "\n",
    "    listOfAllConnectedPoints = [jawPoints,rigthEyebrowPoints,leftEyebrowPoints,\n",
    "                                noseRidgePoints,noseBasePoints,\n",
    "                                rightEyePoints,leftEyePoints,outerMouthPoints,innerMouthPoints]\n",
    "\n",
    "    # select a random subset of 'numVideos' from the available videos\n",
    "    randVideoIDs = videoDF.loc[np.random.choice(videoDF.index,size=numVideos,replace=False),'videoID']\n",
    "\n",
    "    fig, axArray = plt.subplots(nrows=numVideos,ncols=numFramesPerVideo,figsize=(14,18))\n",
    "    for i, videoID in enumerate(randVideoIDs):\n",
    "        # load video\n",
    "        videoFile = np.load(fullPaths[videoID])\n",
    "        colorImages = videoFile['colorImages']\n",
    "        boundingBox = videoFile['boundingBox']\n",
    "        landmarks2D = videoFile['landmarks2D']\n",
    "        landmarks3D = videoFile['landmarks3D']\n",
    "############################################################\n",
    "\n",
    "        \"\"\"selectedFrames = (framesToShowFromVideo*(colorImages.shape[3]-1)).astype(int)\n",
    "        for j, frameInd in enumerate(selectedFrames):\n",
    "            \n",
    "            axArray[i][j].imshow(colorImages[:,:,:,frameInd])\n",
    "            axArray[i][j].scatter(x=landmarks2D[:,0,frameInd],y=landmarks2D[:,1,frameInd],s=9,c='r')\n",
    "            for conPts in listOfAllConnectedPoints:\n",
    "                xPts = landmarks2D[conPts[0]:conPts[-1],0,frameInd]\n",
    "                yPts = landmarks2D[conPts[0]:conPts[-1],1,frameInd]\n",
    "\n",
    "                if conPts == [36,42] or conPts == [42,48] or conPts == [48,60] or conPts == [60,68]:\n",
    "                    xPts=np.concatenate((xPts, [xPts[0]]))\n",
    "                    yPts=np.concatenate((yPts, [yPts[0]]))\n",
    "\n",
    "                axArray[i][j].plot(xPts,yPts,c='w',lw=1)\n",
    "            axArray[i][j].set_title('\"%s\" (t=%d)' %(videoID,frameInd), fontsize=12)\n",
    "            axArray[i][j].set_axis_off()\n",
    "        \"\"\"\n",
    "        #######################################\n",
    "\n",
    "\n",
    "    capture = cv2.VideoCapture(videoFile )\n",
    "\n",
    "    while (capture.isOpened()):\n",
    "\n",
    "        ret, frame = capture.read()\n",
    "        if ret:\n",
    "\n",
    "            cv2.imshow('Video Stream', frame)\n",
    "\n",
    "\n",
    "\n",
    "        else:\n",
    "            break\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    capture.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "            \n",
    "#points_vis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show several 3D keypoints\n",
    "numVideos = 4\n",
    "framesToShowFromVideo = np.array([0.2,0.5,0.8])\n",
    "numFramesPerVideo = len(framesToShowFromVideo)\n",
    "\n",
    "# select a random subset of 'numVideos' from the available videos\n",
    "randVideoIDs = videoDF.loc[np.random.choice(videoDF.index,size=numVideos,replace=False),'videoID']\n",
    "\n",
    "fig = plt.figure(figsize=(14,14))\n",
    "for i, videoID in enumerate(randVideoIDs):\n",
    "    # load video\n",
    "    videoFile = np.load(fullPaths[videoID])\n",
    "    colorImages = videoFile['colorImages']\n",
    "    boundingBox = videoFile['boundingBox']\n",
    "    landmarks2D = videoFile['landmarks2D']\n",
    "    landmarks3D = videoFile['landmarks3D']\n",
    "\n",
    "    # select frames and show their content\n",
    "    selectedFrames = (framesToShowFromVideo*(colorImages.shape[3]-1)).astype(int)\n",
    "    for j, frameInd in enumerate(selectedFrames):\n",
    "        subplotInd = i*numFramesPerVideo + j+1\n",
    "        ax = fig.add_subplot(numVideos, numFramesPerVideo, subplotInd, projection='3d')\n",
    "        ax.scatter(landmarks3D[:,0,frameInd], landmarks3D[:,1,frameInd], landmarks3D[:,2,frameInd],c='r')\n",
    "        \n",
    "        ###ax.imshow(inImages[:,:,:,frameInd])# remove this SIWAR if not working\n",
    "        \n",
    "        for conPts in listOfAllConnectedPoints:\n",
    "            xPts = landmarks3D[conPts[0]:conPts[-1],0,frameInd]\n",
    "            yPts = landmarks3D[conPts[0]:conPts[-1],1,frameInd]\n",
    "            zPts = landmarks3D[conPts[0]:conPts[-1],2,frameInd]\n",
    "            if conPts == [36,42] or conPts == [42,48] or conPts == [48,60] or conPts == [60,68]:\n",
    "                xPts=np.concatenate((xPts, [xPts[0]]))\n",
    "                yPts=np.concatenate((yPts, [yPts[0]]))\n",
    "                zPts=np.concatenate((zPts, [zPts[0]]))\n",
    "                \n",
    "            \n",
    "            ax.plot3D(xPts,yPts,zPts,color='g')         \n",
    "        ax.set_xlim(ax.get_xlim()[::-1])\n",
    "        ax.view_init(elev=96, azim=90)\n",
    "        ax.set_title('\"%s\" (t=%d)' %(videoID,frameInd), fontsize=12)\n",
    "        \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect all 2D and 3D shapes from all frames from all videos to a single numpy array matrix\n",
    "totalNumberOfFrames = videoDF['videoDuration'].sum()\n",
    "landmarks2D_all = np.zeros((68,2,int(totalNumberOfFrames)))\n",
    "landmarks3D_all = np.zeros((68,3,int(totalNumberOfFrames)))\n",
    "\n",
    "shapeIndToVideoID = {} # dictionary for later useage\n",
    "endInd = 0\n",
    "for i, videoID in enumerate(videoDF['videoID']):\n",
    "    \n",
    "    # load video\n",
    "    videoFile = np.load(fullPaths[videoID])\n",
    "    landmarks2D = videoFile['landmarks2D']\n",
    "    landmarks3D = videoFile['landmarks3D']\n",
    "\n",
    "    startInd = endInd\n",
    "    endInd   = startInd + landmarks2D.shape[2]\n",
    "\n",
    "    # store in one big array\n",
    "    landmarks2D_all[:,:,startInd:endInd] = landmarks2D\n",
    "    landmarks3D_all[:,:,startInd:endInd] = landmarks3D\n",
    "    \n",
    "    # make sure we keep track of the mapping to the original video and frame\n",
    "    for videoFrameInd, shapeInd in enumerate(range(startInd,endInd)):\n",
    "        shapeIndToVideoID[shapeInd] = (videoID, videoFrameInd)\n",
    "\n",
    "# center the shapes around zero\n",
    "# i.e. such that for each frame the mean x,y,z coordinates will be zero\n",
    "# or in math terms: Xc = X - mean(X), Yc = Y - mean(Y), Zc = Z - mean(Z)\n",
    "landmarks2D_centered = np.zeros(landmarks2D_all.shape)\n",
    "landmarks2D_centered = landmarks2D_all - np.tile(landmarks2D_all.mean(axis=0),[68,1,1])\n",
    "\n",
    "landmarks3D_centered = np.zeros(landmarks3D_all.shape)\n",
    "landmarks3D_centered = landmarks3D_all - np.tile(landmarks3D_all.mean(axis=0),[68,1,1])\n",
    "\n",
    "# normalize the shapes such that they have the same scale\n",
    "# i.e. such that for each frame the mean euclidian distance from the shape center will be one\n",
    "# or in math terms: mean( sqrt(dX^2 + dY^2 + dZ^2) ) = 1 \n",
    "landmarks2D_normlized = np.zeros(landmarks2D_all.shape)\n",
    "landmarks2D_normlized = landmarks2D_centered / np.tile(np.sqrt((landmarks2D_centered**2).sum(axis=1)).mean(axis=0), [68,2,1])\n",
    "\n",
    "landmarks3D_normlized = np.zeros(landmarks3D_all.shape)\n",
    "landmarks3D_normlized = landmarks3D_centered / np.tile(np.sqrt((landmarks3D_centered**2).sum(axis=1)).mean(axis=0), [68,3,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% check the 2D normalization and verify that everything is as expected\n",
    "# select random several frames to be used as test cases\n",
    "np.random.seed(2)\n",
    "\n",
    "listOfShapeColors = ['r','g','b','m','y','c','k']\n",
    "numShapesToPresent = len(listOfShapeColors)\n",
    "listOfShapeInds = np.random.choice(range(int(totalNumberOfFrames)),size=numShapesToPresent,replace=False)\n",
    "\n",
    "plt.close('all')\n",
    "plt.figure(figsize=(14,10))\n",
    "plt.suptitle('Shape Normalization Stages',fontsize=35)\n",
    "plt.subplot(1,3,1)\n",
    "for k,shapeInd in enumerate(listOfShapeInds):\n",
    "    plt.scatter(landmarks2D_all[:,0,shapeInd], -landmarks2D_all[:,1,shapeInd], s=15, c=listOfShapeColors[k])\n",
    "    for conPts in listOfAllConnectedPoints:\n",
    "        xPts =  landmarks2D_all[conPts[0]:conPts[-1],0,shapeInd]\n",
    "        yPts = -landmarks2D_all[conPts[0]:conPts[-1],1,shapeInd]\n",
    "        if conPts == [36,42] or conPts == [42,48] or conPts == [48,60] or conPts == [60,68]:\n",
    "            xPts=np.concatenate((xPts, [xPts[0]]))\n",
    "            yPts=np.concatenate((yPts, [yPts[0]]))\n",
    "             \n",
    "        plt.plot(xPts,yPts,c=listOfShapeColors[k],lw=1)\n",
    "plt.axis('off'); plt.title('Original Shapes', fontsize=20)\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "for k,shapeInd in enumerate(listOfShapeInds):\n",
    "    plt.scatter(landmarks2D_centered[:,0,shapeInd], -landmarks2D_centered[:,1,shapeInd], s=15, c=listOfShapeColors[k])\n",
    "    for conPts in listOfAllConnectedPoints:\n",
    "        xPts =  landmarks2D_centered[conPts[0]:conPts[-1],0,shapeInd]\n",
    "        yPts = -landmarks2D_centered[conPts[0]:conPts[-1],1,shapeInd]\n",
    "        if conPts == [36,42] or conPts == [42,48] or conPts == [48,60] or conPts == [60,68]:\n",
    "            xPts=np.concatenate((xPts, [xPts[0]]))\n",
    "            yPts=np.concatenate((yPts, [yPts[0]]))\n",
    "           \n",
    "        plt.plot(xPts,yPts,c=listOfShapeColors[k],lw=1)\n",
    "plt.axis('off'); plt.title('Centered Shapes', fontsize=20)\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "for k,shapeInd in enumerate(listOfShapeInds):\n",
    "    plt.scatter(landmarks2D_normlized[:,0,shapeInd], -landmarks2D_normlized[:,1,shapeInd], s=15, c=listOfShapeColors[k])\n",
    "    for conPts in listOfAllConnectedPoints:\n",
    "        xPts =  landmarks2D_normlized[conPts[0]:conPts[-1],0,shapeInd]\n",
    "        yPts = -landmarks2D_normlized[conPts[0]:conPts[-1],1,shapeInd]\n",
    "        if conPts == [36,42] or conPts == [42,48] or conPts == [48,60] or conPts == [60,68]:\n",
    "            xPts=np.concatenate((xPts, [xPts[0]]))\n",
    "            yPts=np.concatenate((yPts, [yPts[0]]))\n",
    "           \n",
    "        plt.plot(xPts,yPts,c=listOfShapeColors[k],lw=1)\n",
    "plt.axis('off'); plt.title('Normlized Shapes', fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% cluster normalized shapes and show the cluster centers\n",
    "numClusters = 16\n",
    "normalizedShapesTable = np.reshape(landmarks2D_normlized, [68*2, landmarks2D_normlized.shape[2]]).T\n",
    "\n",
    "shapesModel = cluster.KMeans(n_clusters=numClusters, n_init=5, random_state=1).fit(normalizedShapesTable[::2,:])\n",
    "clusterAssignment = shapesModel.predict(normalizedShapesTable)\n",
    "\n",
    "plt.figure(figsize=(14,14))\n",
    "numRowsAndCols = int(np.ceil(np.sqrt(numClusters)))\n",
    "for i in range(numClusters):\n",
    "    plt.subplot(numRowsAndCols,numRowsAndCols,i+1);\n",
    "    currClusterShape = np.reshape(shapesModel.cluster_centers_[i,:], [68,2])\n",
    "    plt.scatter(x=currClusterShape[:,0],y=-currClusterShape[:,1],s=20,c='r')\n",
    "    for conPts in listOfAllConnectedPoints:\n",
    "        xPts =  currClusterShape[conPts[0]:conPts[-1],0]\n",
    "        yPts = -currClusterShape[conPts[0]:conPts[-1],1]\n",
    "        if conPts == [36,42] or conPts == [42,48] or conPts == [48,60] or conPts == [60,68]:\n",
    "            xPts=np.concatenate((xPts, [xPts[0]]))\n",
    "            yPts=np.concatenate((yPts, [yPts[0]]))\n",
    "           \n",
    "        plt.plot(xPts,yPts,c='g',lw=1)\n",
    "    plt.title('cluster %d' %(i),fontsize=15)\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% show several original images that are assigned to a particular cluster\n",
    "selectedCluster = 15\n",
    "numRows = 4; numCols = 4;\n",
    "\n",
    "shapeIndsAssignedToCluster = np.nonzero(clusterAssignment == selectedCluster)[0]\n",
    "listOfShapeInds = np.random.choice(shapeIndsAssignedToCluster ,size=numRows*numCols,replace=False)\n",
    "\n",
    "plt.figure(figsize=(14,14))\n",
    "for i, shapeInd in enumerate(listOfShapeInds):\n",
    "    # load video and pickout the relevent frame\n",
    "    videoID  = shapeIndToVideoID[shapeInd][0]\n",
    "    frameInd = shapeIndToVideoID[shapeInd][1]    \n",
    "    videoFile = np.load(fullPaths[videoID])\n",
    "    image = videoFile['colorImages'][:,:,:,frameInd]\n",
    "    \n",
    "    # show the image\n",
    "    plt.subplot(numRows,numCols,i+1);\n",
    "    plt.imshow(image); plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% show several original images that are assigned to a particular cluster\n",
    "selectedCluster = 2\n",
    "numRows = 4; numCols = 4;\n",
    "\n",
    "shapeIndsAssignedToCluster = np.nonzero(clusterAssignment == selectedCluster)[0]\n",
    "listOfShapeInds = np.random.choice(shapeIndsAssignedToCluster ,size=numRows*numCols,replace=False)\n",
    "\n",
    "plt.figure(figsize=(14,14))\n",
    "for i, shapeInd in enumerate(listOfShapeInds):\n",
    "    # load video and pickout the relevent frame\n",
    "    videoID  = shapeIndToVideoID[shapeInd][0]\n",
    "    frameInd = shapeIndToVideoID[shapeInd][1]    \n",
    "    videoFile = np.load(fullPaths[videoID])\n",
    "    image = videoFile['colorImages'][:,:,:,frameInd]\n",
    "    \n",
    "    # show the image\n",
    "    plt.subplot(numRows,numCols,i+1);\n",
    "    plt.imshow(image); plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% define shape normalization utility functions\n",
    "def NormlizeShapes(shapesImCoords):\n",
    "    (numPoints, numDims, _) = shapesImCoords.shape\n",
    "    \"\"\"shapesNomalized, scaleFactors, meanCoords  = NormlizeShapes(shapesImCoords)\"\"\"\n",
    "    \n",
    "    # calc mean coords and subtract from shapes    \n",
    "    meanCoords = shapesImCoords.mean(axis=0)\n",
    "    shapesCentered = np.zeros(shapesImCoords.shape)\n",
    "    shapesCentered = shapesImCoords - np.tile(meanCoords,[numPoints,1,1])\n",
    "\n",
    "    # calc scale factors and divide shapes\n",
    "    scaleFactors = np.sqrt((shapesCentered**2).sum(axis=1)).mean(axis=0)\n",
    "    shapesNormlized = np.zeros(shapesCentered.shape)\n",
    "    shapesNormlized = shapesCentered / np.tile(scaleFactors, [numPoints,numDims,1])\n",
    "\n",
    "    return shapesNormlized, scaleFactors, meanCoords\n",
    "\n",
    "\n",
    "def TransformShapeBackToImageCoords(shapesNomalized, scaleFactors, meanCoords):\n",
    "    \"\"\"shapesImCoords_rec = TransformShapeBackToImageCoords(shapesNomalized, scaleFactors, meanCoords)\"\"\"\n",
    "    (numPoints, numDims, _) = shapesNomalized.shape\n",
    "    \n",
    "    # move back to the correct scale\n",
    "    shapesCentered = shapesNomalized * np.tile(scaleFactors, [numPoints,numDims,1])\n",
    "    # move back to the correct location\n",
    "    shapesImCoords = shapesCentered + np.tile(meanCoords,[numPoints,1,1])\n",
    "    \n",
    "    return shapesImCoords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Normalize 2D and 3D shapes\n",
    "\n",
    "# collect all 2D and 3D shapes from all frames from all videos to a single numpy array matrix\n",
    "totalNumberOfFrames = videoDF['videoDuration'].sum()\n",
    "landmarks2D_all = np.zeros((68,2,int(totalNumberOfFrames)))\n",
    "landmarks3D_all = np.zeros((68,3,int(totalNumberOfFrames)))\n",
    "\n",
    "shapeIndToVideoID = {} # dictionary for later useage\n",
    "endInd = 0\n",
    "for i, videoID in enumerate(videoDF['videoID']):\n",
    "    \n",
    "    # load video\n",
    "    videoFile = np.load(fullPaths[videoID])\n",
    "    landmarks2D = videoFile['landmarks2D']\n",
    "    landmarks3D = videoFile['landmarks3D']\n",
    "\n",
    "    startInd = endInd\n",
    "    endInd   = startInd + landmarks2D.shape[2]\n",
    "\n",
    "    # store in one big array\n",
    "    landmarks2D_all[:,:,startInd:endInd] = landmarks2D\n",
    "    landmarks3D_all[:,:,startInd:endInd] = landmarks3D\n",
    "    \n",
    "    # make sure we keep track of the mapping to the original video and frame\n",
    "    for videoFrameInd, shapeInd in enumerate(range(startInd,endInd)):\n",
    "        shapeIndToVideoID[shapeInd] = (videoID, videoFrameInd)\n",
    "\n",
    "# normlize shapes\n",
    "landmarks2D_normlized, _, _  = NormlizeShapes(landmarks2D_all)\n",
    "landmarks3D_normlized, _, _  = NormlizeShapes(landmarks3D_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jawPoints          = np.arange(0,17)\n",
    "rigthEyebrowPoints = np.arange(17,22)\n",
    "leftEyebrowPoints  = np.arange(22,27)\n",
    "noseRidgePoints    = np.arange(27,31)\n",
    "noseBasePoints     = np.arange(31,36)\n",
    "rightEyePoints     = np.arange(36,42)\n",
    "rightEyePoints = np.concatenate((rightEyePoints,[rightEyePoints[0]]))\n",
    "leftEyePoints      = np.arange(42,48)\n",
    "leftEyePoints = np.concatenate((leftEyePoints,[leftEyePoints[0]]))\n",
    "outerMouthPoints   = np.arange(48,60)\n",
    "outerMouthPoints = np.concatenate((outerMouthPoints,[outerMouthPoints[0]]))\n",
    "innerMouthPoints   = np.arange(60,68)\n",
    "innerMouthPoints = np.concatenate((innerMouthPoints,[innerMouthPoints[0]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% define a utility function to show 3D animation\n",
    "def ShowAnimation_3D(landmarks3D):\n",
    "    \n",
    "    landmarks3D = landmarks3D.copy()\n",
    "    landmarks3D[:,0,:] = -landmarks3D[:,0,:]\n",
    "    \n",
    "    xMin = landmarks3D[:,0,:].min()-5\n",
    "    xMax = landmarks3D[:,0,:].max()+5\n",
    "    yMin = landmarks3D[:,1,:].min()-5\n",
    "    yMax = landmarks3D[:,1,:].max()+5\n",
    "    zMin = landmarks3D[:,2,:].min()-5\n",
    "    zMax = landmarks3D[:,2,:].max()+5\n",
    "    \n",
    "    boxCorners = np.array([[xMin,yMin,zMin],\n",
    "                           [xMin,yMin,zMax],\n",
    "                           [xMin,yMax,zMin],\n",
    "                           [xMin,yMax,zMax],\n",
    "                           [xMax,yMin,zMin],\n",
    "                           [xMax,yMin,zMax],\n",
    "                           [xMax,yMax,zMin],\n",
    "                           [xMax,yMax,zMax]])\n",
    "    \n",
    "    traversalOrder = [0,1,3,2,0,4,6,2,6,7,3,7,5,1,5,4]\n",
    "    boxTraceCoords = np.zeros((len(traversalOrder),3))\n",
    "    for i, corner in enumerate(traversalOrder):\n",
    "        boxTraceCoords[i,:] = boxCorners[corner,:]\n",
    "    \n",
    "    trace1   = go.Scatter3d(name='Jawline', x=landmarks3D[:,0,1][jawPoints],y=landmarks3D[:,1,1][jawPoints],z=landmarks3D[:,2,1][jawPoints],\n",
    "                            mode='lines+markers',marker=dict(color = 'blue',opacity=0.7,size = 5))\n",
    "    \n",
    "    trace2   = go.Scatter3d(name='Right Eyebrow',x=landmarks3D[:,0,1][rigthEyebrowPoints],y=landmarks3D[:,1,1][rigthEyebrowPoints],z=landmarks3D[:,2,1][rigthEyebrowPoints],\n",
    "                            mode='lines+markers',marker=dict(color = 'blue',opacity=0.7,size = 5))\n",
    "    \n",
    "    trace3   = go.Scatter3d(name='Left Eyebrow',x=landmarks3D[:,0,1][leftEyebrowPoints],y=landmarks3D[:,1,1][leftEyebrowPoints],z=landmarks3D[:,2,1][leftEyebrowPoints],\n",
    "                            mode='lines+markers',marker=dict(color = 'blue',opacity=0.7,size = 5))\n",
    "    \n",
    "    trace4   = go.Scatter3d(name='Nose Ridge',x=landmarks3D[:,0,1][noseRidgePoints],y=landmarks3D[:,1,1][noseRidgePoints],z=landmarks3D[:,2,1][noseRidgePoints],\n",
    "                            mode='lines+markers',marker=dict(color = 'green',opacity=0.6,size = 5))\n",
    "    \n",
    "    trace5   = go.Scatter3d(name='Nose Base',x=landmarks3D[:,0,1][noseBasePoints],y=landmarks3D[:,1,1][noseBasePoints],z=landmarks3D[:,2,1][noseBasePoints],\n",
    "                            mode='lines+markers',marker=dict(color = 'green',opacity=0.6,size = 5))\n",
    "    \n",
    "    trace6   = go.Scatter3d(name='Right Eye', x=landmarks3D[:,0,1][rightEyePoints],y=landmarks3D[:,1,1][rightEyePoints],z=landmarks3D[:,2,1][rightEyePoints],\n",
    "                            mode='lines+markers',marker=dict(color = 'green',opacity=0.6,size = 5))\n",
    "    \n",
    "    trace7   = go.Scatter3d(name='Left Eye', x=landmarks3D[:,0,1][leftEyePoints],y=landmarks3D[:,1,1][leftEyePoints],z=landmarks3D[:,2,1][leftEyePoints],\n",
    "                            mode='lines+markers',marker=dict(color = 'green',opacity=0.6,size = 5))\n",
    "    \n",
    "    trace8   = go.Scatter3d(name='Outer Mouth', x=landmarks3D[:,0,1][outerMouthPoints],y=landmarks3D[:,1,1][outerMouthPoints],z=landmarks3D[:,2,1][outerMouthPoints],\n",
    "                            mode='lines+markers',marker=dict(color = 'green',opacity=0.6,size = 5))\n",
    "    \n",
    "    trace9   = go.Scatter3d(name='Inner Mouth', x=landmarks3D[:,0,1][innerMouthPoints],y=landmarks3D[:,1,1][innerMouthPoints],z=landmarks3D[:,2,1][innerMouthPoints],\n",
    "                            mode='lines+markers',marker=dict(color = 'green',opacity=0.6,size = 5))\n",
    "        \n",
    "    boxTrace = go.Scatter3d(name='boundingBox', x=boxTraceCoords[:,0],y=boxTraceCoords[:,1],z=boxTraceCoords[:,2],\n",
    "                            mode='lines+markers',marker=dict(color = 'red', opacity=1.0,size = 5))\n",
    "    \n",
    "    data = [trace1, trace2, trace3, trace4, trace5, trace6, trace7, trace8, trace9, boxTrace]\n",
    "    \n",
    "    mfr = []\n",
    "    for t in range(len(landmarks3D[1,1,:])):\n",
    "        mfr.append({'data' :[{'type' : \"scatter3d\",'mode':'lines+markers',\n",
    "                              'x':landmarks3D[:,0,t][jawPoints],'y':landmarks3D[:,1,t][jawPoints],'z':landmarks3D[:,2,t][jawPoints]},\n",
    "                             {'type' : \"scatter3d\",'mode':'lines+markers',\n",
    "                              'x':landmarks3D[:,0,t][rigthEyebrowPoints],'y':landmarks3D[:,1,t][rigthEyebrowPoints],'z':landmarks3D[:,2,t][rigthEyebrowPoints]},\n",
    "                             {'type' : \"scatter3d\",'mode':'lines+markers',\n",
    "                              'x':landmarks3D[:,0,t][leftEyebrowPoints],'y':landmarks3D[:,1,t][leftEyebrowPoints],'z':landmarks3D[:,2,t][leftEyebrowPoints]},\n",
    "                             {'type' : \"scatter3d\",'mode':'lines+markers',\n",
    "                              'x':landmarks3D[:,0,t][noseRidgePoints],'y':landmarks3D[:,1,t][noseRidgePoints],'z':landmarks3D[:,2,t][noseRidgePoints]},\n",
    "                             {'type' : \"scatter3d\",'mode':'lines+markers',\n",
    "                              'x':landmarks3D[:,0,t][noseBasePoints],'y':landmarks3D[:,1,t][noseBasePoints],'z':landmarks3D[:,2,t][noseBasePoints]},\n",
    "                             {'type' : \"scatter3d\",'mode':'lines+markers',\n",
    "                              'x':landmarks3D[:,0,t][rightEyePoints],'y':landmarks3D[:,1,t][rightEyePoints],'z':landmarks3D[:,2,t][rightEyePoints]},\n",
    "                             {'type' : \"scatter3d\",'mode':'lines+markers',\n",
    "                              'x':landmarks3D[:,0,t][leftEyePoints],'y':landmarks3D[:,1,t][leftEyePoints],'z':landmarks3D[:,2,t][leftEyePoints]},\n",
    "                             {'type' : \"scatter3d\",'mode':'lines+markers',\n",
    "                              'x':landmarks3D[:,0,t][outerMouthPoints],'y':landmarks3D[:,1,t][outerMouthPoints],'z':landmarks3D[:,2,t][outerMouthPoints]},\n",
    "                             {'type' : \"scatter3d\",'mode':'lines+markers',\n",
    "                              'x':landmarks3D[:,0,t][innerMouthPoints],'y':landmarks3D[:,1,t][innerMouthPoints],'z':landmarks3D[:,2,t][innerMouthPoints]},\n",
    "                             {'type' : \"scatter3d\",'mode':'lines+markers',\n",
    "                             'x':boxTraceCoords[:,0],'y':boxTraceCoords[:,1],'z':boxTraceCoords[:,2]}]})\n",
    "                                 \n",
    "    \n",
    "    layout = go.Layout(width=800, height=800, title='3D Face Shape Animation',\n",
    "                       scene=dict(camera=dict(up     = dict(x= 0, y=-1.0, z=0),\n",
    "                                              center = dict(x= 0, y= 0.0, z=0),\n",
    "                                              eye    = dict(x= 0, y= 0.7, z=2),\n",
    "                                             )\n",
    "                                 ),\n",
    "                        updatemenus=[dict(type='buttons', showactive=False,\n",
    "                                            y=1,\n",
    "                                            x=1,\n",
    "                                            xanchor='right',\n",
    "                                            yanchor='top',\n",
    "                                            pad=dict(t=0, r=10),\n",
    "                                            buttons=[dict(\n",
    "                                                        label='Play Animation',\n",
    "                                                        method='animate',\n",
    "                                                        args=[None, dict(frame       = dict(duration=0.04, redraw=True), \n",
    "                                                                         transition  = dict(duration=0),\n",
    "                                                                         fromcurrent = True,\n",
    "                                                                         mode = 'immediate'\n",
    "                                                                        )\n",
    "                                                             ]\n",
    "                                                         )\n",
    "                                                    ]\n",
    "                                           )\n",
    "                                      ]\n",
    "                      )\n",
    "                                                    \n",
    "    fig = dict(data=data, layout=layout, frames=mfr)\n",
    "    py.iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import decomposition\n",
    "from scipy import signal\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import matplotlib\n",
    "import plotly.offline as py\n",
    "import plotly.graph_objs as go\n",
    "#import imageio\n",
    "import glob\n",
    "\n",
    "py.init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% load a 3D landmarks sequence and present it\n",
    "\n",
    "personToUse ='Ali_Abbas_2'\n",
    "videoFile = np.load(fullPaths[personToUse])\n",
    "landmarks3D_curr = videoFile['landmarks3D']\n",
    "\n",
    "ShowAnimation_3D(landmarks3D_curr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% build 3D shape model\n",
    "numComponents = 30\n",
    "\n",
    "normalizedShapesTable = np.reshape(landmarks3D_normlized, [68*3, landmarks3D_normlized.shape[2]]).T\n",
    "shapesModel = decomposition.PCA(n_components=numComponents, whiten=True, random_state=1).fit(normalizedShapesTable)\n",
    "print('Total explained percent by PCA model with %d components is %.1f%s' %(numComponents, 100*shapesModel.explained_variance_ratio_.sum(),'%'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% interpret the shapes using our shape model (project and reconstruct)\n",
    "\n",
    "# normlize shapes (and keep the scale factors and mean coords for later reconstruction)\n",
    "landmarks3D_norm, scaleFactors, meanCoords  = NormlizeShapes(landmarks3D_curr)\n",
    "# convert to matrix form\n",
    "landmarks3D_norm_table = np.reshape(landmarks3D_norm, [68*3, landmarks3D_norm.shape[2]]).T\n",
    "# project onto shapes model and reconstruct\n",
    "landmarks3D_norm_table_rec = shapesModel.inverse_transform(shapesModel.transform(landmarks3D_norm_table))\n",
    "# convert back to shapes (numKeypoint, numDims, numFrames)\n",
    "landmarks3D_norm_rec = np.reshape(landmarks3D_norm_table_rec.T, [68, 3, landmarks3D_norm.shape[2]])\n",
    "# transform back to image coords\n",
    "landmarks3D_curr_rec = TransformShapeBackToImageCoords(landmarks3D_norm_rec, scaleFactors, meanCoords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the new animation\n",
    "ShowAnimation_3D(landmarks3D_curr_rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% plot x(t), y(t), z(t) for several keypoints before and after filtering\n",
    "selectedKeypointInds    = [ 30, 33,  36, 39,  42, 45,  51, 57,  62, 66,  48, 54]\n",
    "selectedKeypointColors  = ['g','g', 'r','m', 'm','r', 'b','b', 'g','g', 'y','y']\n",
    "selectedKeypointStrings = ['nose tip', 'nose base',  'right eye outer','right eye inner',  'left eye inner','left eye outer',\n",
    "                           'outer mouth top','outer mouth bottom',  'inner mouth top','inner mouth bottom',\n",
    "                           'right mouth corner','left mouth corner']\n",
    "\n",
    "plt.figure(figsize=(13,11)); plt.suptitle('Original Traces', fontsize=22)\n",
    "for subplotInd, yLabel in enumerate(['x(t)','y(t)','z(t)']):\n",
    "    plt.subplot(3,1,subplotInd+1); plt.ylabel(yLabel,fontsize=20)\n",
    "    for k,c,legendLabel in zip(selectedKeypointInds,selectedKeypointColors,selectedKeypointStrings):\n",
    "        plt.plot(landmarks3D_curr[k,subplotInd,:],c=c,label=legendLabel)\n",
    "    if subplotInd == 0: \n",
    "        plt.legend(bbox_to_anchor=(0,1,1,0), shadow=True,\n",
    "                   loc=3, ncol=4, mode=\"expand\", borderaxespad=0, fontsize=12)\n",
    "plt.xlabel('time [frame]',fontsize=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(13,11)); plt.suptitle('Original Vs. \"Spatially\" Filtered Traces', fontsize=22)\n",
    "for subplotInd, yLabel in enumerate(['x(t)','y(t)','z(t)']):\n",
    "    plt.subplot(3,1,subplotInd+1); plt.ylabel(yLabel,fontsize=25)\n",
    "    plt.plot(landmarks3D_curr[selectedKeypointInds,subplotInd,:].T,c='r')\n",
    "    plt.plot(landmarks3D_curr_rec[selectedKeypointInds,subplotInd,:].T,c='b')\n",
    "plt.xlabel('time [frame]',fontsize=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% apply temporal filtering on the 3D points and show filtered signals\n",
    "filterHalfLength = 2\n",
    "temporalFilter = np.ones((1,1,2*filterHalfLength+1))\n",
    "temporalFilter = temporalFilter / temporalFilter.sum()\n",
    "\n",
    "startTileBlock = np.tile(landmarks3D_curr_rec[:,:,0][:,:,np.newaxis],[1,1,filterHalfLength])\n",
    "endTileBlock = np.tile(landmarks3D_curr_rec[:,:,-1][:,:,np.newaxis],[1,1,filterHalfLength])\n",
    "landmarks3D_curr_rec_padded = np.dstack((startTileBlock,landmarks3D_curr_rec,endTileBlock))\n",
    "landmarks3D_curr_rec_filtered = signal.convolve(landmarks3D_curr_rec_padded, temporalFilter, mode='valid', method='fft')\n",
    "\n",
    "plt.figure(figsize=(13,11)); plt.suptitle('Original Vs. Spatio-Temporally Filtered Traces', fontsize=22)\n",
    "for subplotInd, yLabel in enumerate(['x(t)','y(t)','z(t)']):\n",
    "    plt.subplot(3,1,subplotInd+1); plt.ylabel(yLabel,fontsize=20)\n",
    "    plt.plot(landmarks3D_curr[selectedKeypointInds,subplotInd,:].T,c='r')\n",
    "    plt.plot(landmarks3D_curr_rec_filtered[selectedKeypointInds,subplotInd,:].T,c='b')\n",
    "plt.xlabel('time [frame]',fontsize=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% show animation of the temporally filtered 3D points\n",
    "ShowAnimation_3D(landmarks3D_curr_rec_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% helper function: create videos with keypoints overlaid for each of the 3 processing stages\n",
    "def CreateVideosWithMarkingsSideBySide(colorImages, landmarks3D_curr, landmarks3D_curr_rec, landmarks3D_curr_rec_filtered):\n",
    "    imageWithMarkings_orig   = colorImages.copy()\n",
    "    imageWithMarkings_sp     = colorImages.copy()\n",
    "    imageWithMarkings_sp_tmp = colorImages.copy()\n",
    "    \n",
    "    # paint requested channel\n",
    "    channelToMark = 1\n",
    "    for frame in range(colorImages.shape[3]):\n",
    "        for k in range(landmarks3D_curr.shape[0]):\n",
    "            for dh in [-1,0,1]:\n",
    "                for dw in [-1,0,1]:\n",
    "                    locH_orig   = int(np.round(landmarks3D_curr[k,1,frame])) + dh\n",
    "                    locW_orig   = int(np.round(landmarks3D_curr[k,0,frame])) + dw\n",
    "                    \n",
    "                    locH_sp     = int(np.round(landmarks3D_curr_rec[k,1,frame])) + dh\n",
    "                    locW_sp     = int(np.round(landmarks3D_curr_rec[k,0,frame])) + dw\n",
    "                    \n",
    "                    locH_sp_tmp = int(np.round(landmarks3D_curr_rec_filtered[k,1,frame])) + dh\n",
    "                    locW_sp_tmp = int(np.round(landmarks3D_curr_rec_filtered[k,0,frame])) + dw\n",
    "                    try:\n",
    "                        imageWithMarkings_orig[locH_orig,locW_orig,channelToMark,frame] = 255\n",
    "                        imageWithMarkings_sp[locH_sp,locW_sp,channelToMark,frame] = 255\n",
    "                        imageWithMarkings_sp_tmp[locH_sp_tmp,locW_sp_tmp,channelToMark,frame] = 255\n",
    "                    except:\n",
    "                        pass\n",
    "            \n",
    "    SideBySide = np.hstack((imageWithMarkings_orig,imageWithMarkings_sp,imageWithMarkings_sp_tmp))\n",
    "    return SideBySide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SideBySide = CreateVideosWithMarkingsSideBySide(videoFile['colorImages'], landmarks3D_curr, landmarks3D_curr_rec, landmarks3D_curr_rec_filtered)\n",
    "\n",
    "#%% show video animations\n",
    "def WriteColorVideo(video, filename='sample.gif', fps=20):\n",
    "    writer = imageio.get_writer(filename, fps=fps)\n",
    "    for frame in range(video.shape[-1]):\n",
    "        writer.append_data(video[:, :, :, frame])\n",
    "    writer.close()\n",
    "\n",
    "#WriteColorVideo(SideBySide,'processingStages.gif',fps=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "WriteColorVideo(SideBySide,'processingStages.gif',fps=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "im = Image.open('processingStages.gif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSEC_PER_FRAME    = 40\n",
    "MSEC_REPEAT_DELAY = 500\n",
    "\n",
    "# Create an animated GIF file from a sequence of images\n",
    "def build_gif(inImages, fname=None, show_gif=True, save_gif=True, title=''):\n",
    "    fig = plt.figure(figsize=(12,5))\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.set_axis_off()\n",
    "    fig.subplots_adjust(left=0, bottom=0, right=1, top=1, \n",
    "                        wspace=None, hspace=None)  # removes white border\n",
    "    \n",
    "    imgs = [ (ax.imshow(inImages[:,:,:,frame]), \n",
    "              ax.set_title(title), \n",
    "              ax.annotate(frame,(5,5))) for frame in range(inImages.shape[3]) ] \n",
    "\n",
    "    img_anim = animation.ArtistAnimation(fig, imgs, interval=MSEC_PER_FRAME, \n",
    "                                         repeat_delay=MSEC_REPEAT_DELAY, blit=False)\n",
    "    if save_gif:\n",
    "        print('Writing:', fname)\n",
    "        img_anim.save(fname, writer='imagemagick')\n",
    "    if show_gif:\n",
    "        plt.show();\n",
    "    plt.clf() # clearing the figure when done prevents a memory leak "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titleStr = 'original video | spatially filtered | spatio-temporally filtered'\n",
    "build_gif(SideBySide, fname='smoothing_stages_side_by_side.gif', show_gif=False, save_gif=True, title=titleStr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "side1=[]\n",
    "for i in SideBySide:\n",
    "    side2=[]\n",
    "    for j in i:\n",
    "        side2.append(j[:,0])\n",
    "    side1.append(side2)\n",
    "    \n",
    "side1 = np.array(side1)\n",
    "side1.shape\n",
    "#(99, 327, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "side1 = np.empty((SideBySide.shape[0],SideBySide.shape[1],SideBySide.shape[2],SideBySide.shape[3]), dtype=object)\n",
    "side1 = SideBySide\n",
    "print(side1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "capture = cv2.VideoCapture(0 )\n",
    "w=int(capture.get(3))\n",
    "h=int(capture.get(4))\n",
    "#fourcc = cv2.VideoWriter_fourcc(*'XVID') \n",
    "#video_writer = cv2.VideoWriter(\"output.avi\", fourcc, 25, (w, h))   \n",
    "\n",
    "while (capture.isOpened()):\n",
    "\n",
    "    ret, frame = capture.read()\n",
    "    if ret:\n",
    "        #print(\"frame : \", frame)\n",
    "        print(\"shape : \", frame.shape)\n",
    "        #print(type(frame))\n",
    "      \n",
    "\n",
    "        #video_writer.write(frame)\n",
    "        cv2.imshow('Video Stream', frame)\n",
    "\n",
    "    else:\n",
    "        break\n",
    "\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "capture.release()\n",
    "#video_writer.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% helper function: create videos with keypoints overlaid for each of the 3 processing stages\n",
    "def CreateVideosWithMarkingsSideBySide(colorImages, landmarks3D_curr, landmarks3D_curr_rec, landmarks3D_curr_rec_filtered):\n",
    "    imageWithMarkings_orig   = colorImages.copy()\n",
    "    imageWithMarkings_sp     = colorImages.copy()\n",
    "    imageWithMarkings_sp_tmp = colorImages.copy()\n",
    "    \n",
    "    # paint requested channel\n",
    "    channelToMark = 1\n",
    "    for frame in range(colorImages.shape[3]):\n",
    "        for k in range(landmarks3D_curr.shape[0]):\n",
    "            for dh in [-1,0,1]:\n",
    "                for dw in [-1,0,1]:\n",
    "                    locH_orig   = int(np.round(landmarks3D_curr[k,1,frame])) + dh\n",
    "                    locW_orig   = int(np.round(landmarks3D_curr[k,0,frame])) + dw\n",
    "                    \n",
    "                    locH_sp     = int(np.round(landmarks3D_curr_rec[k,1,frame])) + dh\n",
    "                    locW_sp     = int(np.round(landmarks3D_curr_rec[k,0,frame])) + dw\n",
    "                    \n",
    "                    locH_sp_tmp = int(np.round(landmarks3D_curr_rec_filtered[k,1,frame])) + dh\n",
    "                    locW_sp_tmp = int(np.round(landmarks3D_curr_rec_filtered[k,0,frame])) + dw\n",
    "                    try:\n",
    "                        imageWithMarkings_orig[locH_orig,locW_orig,channelToMark,frame] = 255\n",
    "                        imageWithMarkings_sp[locH_sp,locW_sp,channelToMark,frame] = 255\n",
    "                        imageWithMarkings_sp_tmp[locH_sp_tmp,locW_sp_tmp,channelToMark,frame] = 255\n",
    "                    except:\n",
    "                        pass\n",
    "            \n",
    "    SideBySide = np.hstack((imageWithMarkings_orig,imageWithMarkings_sp,imageWithMarkings_sp_tmp))\n",
    "    \n",
    "    SideBySide = imageWithMarkings_sp_tmp\n",
    "    return SideBySide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SideBySide = CreateVideosWithMarkingsSideBySide(videoFile['colorImages'], landmarks3D_curr, landmarks3D_curr_rec, landmarks3D_curr_rec_filtered)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSEC_PER_FRAME    = 40\n",
    "MSEC_REPEAT_DELAY = 500\n",
    "\n",
    "def build_gif(inImages, fname=None, show_gif=True, save_gif=True, title=''):\n",
    "    fig = plt.figure(figsize=(12,5))\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.set_axis_off()\n",
    "    fig.subplots_adjust(left=0, bottom=0, right=1, top=1, \n",
    "                        wspace=None, hspace=None)  \n",
    "    \n",
    "    imgs = [ (ax.imshow(inImages[:,:,:,frame]), \n",
    "              ax.set_title(title), \n",
    "              ax.annotate(frame,(5,5))) for frame in range(inImages.shape[3]) ] \n",
    "\n",
    "    img_anim = animation.ArtistAnimation(fig, imgs, interval=MSEC_PER_FRAME, \n",
    "                                         repeat_delay=MSEC_REPEAT_DELAY, blit=False)\n",
    "    if save_gif:\n",
    "        img_anim.save(fname, writer='imagemagick')\n",
    "    if show_gif:\n",
    "        plt.show();\n",
    "    plt.clf() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titleStr = 'original video | spatially filtered | spatio-temporally filtered'\n",
    "build_gif(SideBySide, fname='smoothing_stages_side_by_side.gif', show_gif=False, save_gif=True, title=titleStr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "inImages = SideBySide\n",
    "\n",
    "fig = plt.figure(figsize=(12,5))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_axis_off()\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID') #########################\n",
    "video_writer = cv2.VideoWriter(\"output.avi\", fourcc, 10. ,(99,109)) ########################\n",
    "\n",
    "fig.subplots_adjust(left=0, bottom=0, right=1, top=1, wspace=None, hspace=None)  \n",
    "    \n",
    "imgs = [(ax.imshow(inImages[:,:,:,frame]), ax.set_title(\"gif\"), ax.annotate(frame,(5,5))) for frame in range(inImages.shape[3]) ] \n",
    "\n",
    "#[video_writer.write(inImages[:,:,:,frame]) for frame in range(inImages.shape[3])] #####################\n",
    "\n",
    "[video_writer.write(cv2.resize(inImages[:,:,:,frame],(480,360),interpolation=cv2.INTER_AREA)) for frame in range(inImages.shape[3])]\n",
    "\n",
    "#[cv2.imshow(\"eer\",cv2.resize(inImages[:,:,:,frame],(480,360),interpolation=cv2.INTER_AREA)) for frame in range(inImages.shape[3])]\n",
    "\n",
    "cv2.imshow(\"eer\",(inImages[:,:,:,0]))\n",
    "\n",
    "img_anim = animation.ArtistAnimation(fig, imgs, interval=MSEC_PER_FRAME, repeat_delay=MSEC_REPEAT_DELAY, blit=False)\n",
    "\n",
    "img_anim.save('smoothing_stages_side_by_side.gif', writer='imagemagick')\n",
    "\n",
    "#plt.show()\n",
    "plt.clf() \n",
    "\n",
    "video_writer.release() #######################"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
